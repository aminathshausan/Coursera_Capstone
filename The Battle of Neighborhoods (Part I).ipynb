{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# The Battle of Neighborhoods (Part I)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#####  By: Aminath Shausan"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Background\n\nAs we hit  halfway point in 2020,   this year appears challenging to the residents of Queensland, Australia. With the experience of fires and floods in the beginning of the year and currently the spread of Coronavirus (COVID-19), there are so many uncertainities in  the share market. Meanwhile the Government and  the Reserve Bank of Australia have quickly taken  steps to reduce interest rates and introduced huge stimulus packages to combat these issues, how is COVID-19 affecting the property market in Brisbane? \n\nAccording to research by Hunter Galloway (https://www.huntergalloway.com.au/), the property market in Brisbane has been seen a strong start at the beginning of 2020 and has a very strong housing affordability compared to Sydney and Melbourne. The current price to income ratio required to buy in Brisbane is 5.3 times at a median house price of $524,000. However, not all Brisbane suburbs are equally competitive for home buyers when it comes for long term investment. As per the above mentioned research, some suburbs such as Greenslope, Strathpine, Ferny Hills, Kedron, Oxley, Caloundra   are expected to shine in the property market due to their proximity to the Brisbane CBD. Whilst proximity to Brisbane CBD is a criterior for high demand for home buyers, those who have school aged children prefer to buy houses in a school catchman with a high rank.  Suprisingly, there are some suburbs such as Brisbane CBD, Milton, Kangaroo Point at a risk for investors as some banks may apply stricter criteria to loans, could reduce rental income and may ask for more deposit."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### The Problem\n\nWith the above observation that not every suburb in Brisbane is not equally competitive for investment, I aim to apply machine learning tools to assist people who want to invest in Brisbane housing market to make a sound decision.  The specific business problem which I intend to answer is: which suburbs in Brisbane are suitable for investment in this uncertain economic and pandamic situation?    \n\nIn order to solve this problem, I am going to cluster Brisbane suburbs, in the Greater Brisbane area, according to current real estate median  house prices and venues and essential facilities such as schools, cafes, hospitals and grocery stores in those suburbs.  This clustering will provide to determine which suburbs are best livable according to their median house prices and venues and thus can be recommended to investors.   \n  "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Description of Data and its Application\n\nMedian house value data on the top 1408 Queensland suburbs are extracted from http://house.speakingsame.com/ website. This dataset consists of three columns; Rank, Suburb, Value. The 'Rank' column corresponds to the rank of the each suburb according to its median house price (corresponding to the 'Value' column) and the 'Suburb' column provides the name of the suburb. From this dataset, those rows corresponding to the Greater Brisbane suburbs are filtered. The names of the Greater Brisbane suburbs are collected from Wikipedia (https://en.wikipedia.org/wiki/List_of_Brisbane_suburbs).   \n\nIn the next step, Python's 'geopy' package is used to add location of each Brisbane suburbs.  Then FourSquare API is used to extract venues and essential facilities in each suburb and then this data is merged with the Brisbande house price dataset. Finaly, by performing a k-means clustering on this combined dataset, we will be able to recommend suitable and profitable suburbs to investors.   "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Methodology \n\nThis section describes the data collection and preprocessing, the analysis  and prediction parts. It comprises of the following subsections \n\n1. Data collection and its Study:- webscrape house price data on the top 1408 Queensland suburbs from http://house.speakingsame.com/ and filter those corresponding to Greater Brisbane suburbs given in https://en.wikipedia.org/wiki/List_of_Brisbane_suburbs. Note that the data on all Queensland suburbs is contained in 28 webpages. View the first five rows and size of dataset, rename columns\n2. Preprocessing data:- add suburb location data, produce a map containing suburbs and prices (may need to restrict data to specific budget if required), extract venue  and essential facilities information from FourSquare API, perform onehot encoding.\n3. Modelling :- perform k-means clustering\n4. Prediction:- determine top 10 or 5 clusters\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 1.  Data Collection and its Study \n\nIn this subsection, the median house price data for 1408 Queensland suburbs are collected by  webscraping 28 websites corresponding to  http://house.speakingsame.com/. I will first demonstrate how to collect this data from the first webpage (http://house.speakingsame.com/suburbtop.php?sta=qld&cat=HomePrice&name=&page=0) and filter those data corresponding to the Greater Brisbane suburbs, so that it is easier to learn the structure of the dataset. I will then use a 'for'  loop which runs through this process for all 28 webpages. \n\nLet me first import the required Python libraries for this process."
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Libraries imported.\n"
                }
            ],
            "source": "#import required libraries\nimport numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We also need a list containing all suburbs in the Greater Brisbane suburbs. We form this list using the list of suburbs given in https://en.wikipedia.org/wiki/List_of_Brisbane_suburbs, which distinguishes Greater Brisbane suburbs into 5 categories; inner, northern, southern, eastern and western suburbs. There are altogether 192 suburbs in this list."
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "192\n"
                }
            ],
            "source": "#create a list of  suburb names of Greater Brisbane\ninner_sub = ['Bowen Hills',  'Brisbane', 'East Brisbane', 'Fortitude Valley', 'Herston', 'Highgate Hill', 'Kangaroo Point', 'Kelvin Grove', \n             'New Farm', 'Newstead', 'Paddington', 'Petrie Terrace', 'Red Hill', 'South Brisbane', 'Spring Hill', 'Teneriffe', 'West End', \n             'Woolloongabba']\n\nnorth_sub = ['Albion', 'Alderley', 'Ascot', 'Aspley', 'Bald Hills', 'Banyo', 'Boondall', 'Bracken Ridge', 'Bridgeman Downs', 'Brighton',\n             'Brisbane Airport', 'Carseldine', 'Chermside', 'Chermside West', 'Clayfield',  'Deagon', 'Eagle Farm', 'Everton Park', 'Ferny Grove',\n             'Fitzgibbon', 'Gaythorne', 'Geebung', 'Gordon Park', 'Grange', 'Hamilton', 'Hendra', 'Kalinga', 'Kedron', 'Keperra', 'Lutwyche', \n             'McDowall', 'Mitchelton', 'Myrtletown', 'Newmarket', 'Northgate', 'Nudgee', 'Nudgee Beach', 'Nundah', 'Pinkenba', 'Sandgate',\n             'Shorncliffe', 'Stafford', 'Stafford Heights', 'Taigum', 'Virginia', 'Wavell Heights', 'Wilston', 'Windsor', 'Wooloowin', 'Zillmere']\n\nsouth_sub = ['Acacia Ridge', 'Algester', 'Annerley', 'Archerfield', 'Burbank', 'Calamvale', 'Coopers Plains', 'Darra', 'Doolandella', \n             'Drewvale', 'Durack', 'Dutton Park', 'Eight Mile Plains', 'Ellen Grove', 'Fairfield', 'Forest Lake', 'Greenslopes', 'Heathwood', \n             'Holland Park', 'Holland Park West', 'Inala', 'Karawatha', 'Kuraby', 'Larapinta', 'MacGregor', 'Mackenzie', 'Mansfield', 'Moorooka', \n             'Mount Gravatt', 'Mount Gravatt East', 'Nathan', 'Pallara', 'Parkinson', 'Richlands', 'Robertson', 'Rochedale', 'Rocklea', \n             'Runcorn', 'Salisbury', 'Seventeen Mile Rocks',  'Sinnamon Park', 'Stones Corner', 'Stretton', 'Sumner', 'Sunnybank',\n             'Sunnybank Hills', 'Tarragindi',  'Tennyson', 'Upper Mount Gravatt', 'Wacol', 'Willawong',  'Wishart', 'Yeerongpilly', 'Yeronga']\n\neast_sub = ['Balmoral', 'Belmont', 'Bulimba', 'Camp Hill', 'Cannon Hill', 'Carina', 'Carina Heights', 'Carindale', 'Chandler', 'Coorparoo', \n            'Gumdale', 'Hawthorne', 'Hemmant', 'Lota', 'Lytton', 'Manly', 'Manly West', 'Moreton Island', 'Morningside', 'Murarrie', \n            'Norman Park', 'Port of Brisbane', 'Ransome', 'Seven Hills', 'Tingalpa', 'Wakerley', 'Wynnum', 'Wynnum West']\n\nwest_sub = ['Anstead', 'Ashgrove', 'Auchenflower', 'Bardon', 'Bellbowrie', 'Brookfield', 'Chapel Hill', 'Chelmer', 'Chuwar', 'Corinda', 'Enoggera', \n            'Enoggera Reservoir', 'Fig Tree Pocket', 'Graceville', 'Indooroopilly', 'Jamboree Heights' , 'Jindalee', 'Karana Downs', \n            'Kenmore', 'Kenmore Hills', 'Kholo', 'Lake Manchester', 'Middle Park', 'Milton', 'Moggill', 'Mount Coot-tha', 'Mount Crosby', \n            'Mount Ommaney', 'Oxley', 'Pinjarra Hills', 'Pullenvale', 'Riverhills', 'Seventeen Mile Rocks', 'Sherwood', 'Sinnamon Park', \n            'St Lucia', 'Taringa', 'The Gap', 'Toowong', 'Upper Brookfield', 'Upper Kedron', 'Westlake']\n\n#check length of the list \n#print(len(inner_sub), len(north_sub), len(south_sub), len(east_sub), len(west_sub))\n\n#join the list of suburbs into one list \nsub_list  = inner_sub + north_sub + south_sub + east_sub + west_sub\nprint(len(sub_list))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now lets read data on median house prices from the first webpage (http://house.speakingsame.com/suburbtop.php?sta=qld&cat=HomePrice&name=&page=0) and inspect its size and the first 5 rows."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(51, 3)\n      0                  1           2\n0  Rank             Suburb       Value\n1     1     Jollys Lookout  $2,999,900\n2     2  Sovereign Islands  $2,619,400\n3     3      Mermaid Beach  $2,200,100\n4     4     Sunshine Beach  $1,975,100\n"
                }
            ],
            "source": "#read the table in the http://house.speakingsame.com/suburbtop.php?sta=qld&cat=HomePrice&name=&page=0\n\ndf = pd.read_html('http://house.speakingsame.com/suburbtop.php?sta=qld&cat=HomePrice&name=&page=0')[5]\n\n#check size and 1st few rows\nprint(df.shape)\nprint(df.head(5))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "There are 51 rows and 3 columns in this dataframe. Notice that row 0 actually contains the column names in the actual dataset. So we will rename the columns with these names and drop row 0. This implies that the actual dataframe will consist of 50 rows and 3 columns"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(50, 3)\n  Rank             Suburb       Value\n1    1     Jollys Lookout  $2,999,900\n2    2  Sovereign Islands  $2,619,400\n3    3      Mermaid Beach  $2,200,100\n4    4     Sunshine Beach  $1,975,100\n5    5    Cooroy Mountain  $1,946,600\n"
                }
            ],
            "source": "#rename columns as 'Rank', 'Suburb', 'Value' and drop the first row\ndf.columns = ['Rank', 'Suburb', 'Value']\ndf.drop(df.index[0], inplace=True)\n  \n#check size and 1st few rows\nprint(df.shape)\nprint(df.head())   "
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "22\n50\n"
                }
            ],
            "source": "#check which suburbs in df 'Suburb' columns are also in sub_list \n\ndf_sub = df['Suburb'].tolist()\n#set(df_sub).intersection(sub_list)\ncom_sub = set(df_sub) & set(sub_list)\nprint(len(com_sub))    #There   are 22 common suburbs names in both lists\nprint(len(df_sub))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Lets filter, from df dataframe, those suburbs containing in the list sub_list"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(22, 3)\n   Rank     Suburb       Value\n10   10  Willawong  $1,552,100\n11   11   New Farm  $1,443,500\n15   15  Teneriffe  $1,401,200\n16   16    Gumdale  $1,367,000\n18   18   Hamilton  $1,357,700\n"
                }
            ],
            "source": "#filter suburbs in df which corresponds to those in sub_list\ndf1 = df.query('Suburb in @sub_list')\n#df1 = df.loc[(df['Suburb'].isin(sub_list))] \n\n#check size and 1st few rows\nprint(df1.shape)\nprint(df1.head())   \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, I will write a 'for' loop which does the above process for the 28 webpages containing required data. The urls for each webpage differs by the last number, with the first webpage url ending with 0 (http://house.speakingsame.com/suburbtop.php?sta=qld&cat=HomePrice&name=&page=0), and incrementing by 1 for the next webpage, and the last webpage ending with number 28.   "
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "#webscrap all 28 webpages, filter data, according to suburb names in sub_list\nurls = {page_number:'http://house.speakingsame.com/suburbtop.php?sta=qld&cat=HomePrice&name=&page={}'.format(page_number) \n            for page_number in list(range(0, 29))}\n\n\ndfs ={}       # a dictionary to hold the original (unfiltered) dataframes\ndfnew = {}    # a dictionary to hold the filtered dataframes\n\nfor url in range(0,len(urls)):\n    dfs[url]= (pd.read_html(urls[url])[5])             # read data from webpage\n    dfs[url].columns = ['Rank', 'Suburb', 'Value']     # rename columns\n    dfs[url].drop(dfs[url].index[0], inplace=True)     # drop the first row\n    dfnew[url] = dfs[url].query('Suburb in @sub_list') # filter according to suburb names in the sub_list    \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Check if the size and first 5 rows of dfnew[0] matches with that of df1, whose size is 22 rows and 3 columns"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(22, 3)\n   Rank     Suburb       Value\n10   10  Willawong  $1,552,100\n11   11   New Farm  $1,443,500\n15   15  Teneriffe  $1,401,200\n16   16    Gumdale  $1,367,000\n18   18   Hamilton  $1,357,700\n"
                }
            ],
            "source": "#check if size and 1st 5 rows of dfnew[1] matches with that of df1 above\nprint(dfnew[0].shape)\nprint(dfnew[0].head())  \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Since the size and first 5 rows of df1 and dfnew[0] are the same, we can safely assume that the for loop is correctly extracting data corresponding to those suburbs in sub_list list. Thus we can now combine all dataframes in the dictionary dfnew into a single dataframe.  "
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "scrolled": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(178, 3)\n  Rank     Suburb       Value\n0   10  Willawong  $1,552,100\n1   11   New Farm  $1,443,500\n2   15  Teneriffe  $1,401,200\n3   16    Gumdale  $1,367,000\n4   18   Hamilton  $1,357,700\n"
                }
            ],
            "source": "#merge all dataframes in dfnew dictionary vertically \n\nbrisbane_df = pd.concat(dfnew.values(), ignore_index=True)\nprint(brisbane_df.shape)\nprint(brisbane_df.head())"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Note that the dataframe brisbane_df contains data on 178 suburbs which means that not all suburb median prices in the Greater Brisbane region are given in the webpages  http://house.speakingsame.com/. Thus for illustration purpose and considering time to manually enter house prices for those suburbs not included in the sub_list list, we will analyse data only for those  suburbs in the brisbane_df. "
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "scrolled": true
            },
            "source": "### 2. Preprocess Data "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 3. Modelling"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 4. Prediction"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}